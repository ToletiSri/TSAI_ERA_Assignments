{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3da9546e",
   "metadata": {},
   "source": [
    "# S18 - Part B - VAE with MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34955316",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56d0a08e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SToleti\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\Users\\SToleti\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchaudio\\backend\\utils.py:74: UserWarning: No audio backend is available.\n",
      "  warnings.warn(\"No audio backend is available.\")\n",
      "C:\\Users\\SToleti\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pl_bolts\\__init__.py:11: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(numpy, tp_name):\n",
      "C:\\Users\\SToleti\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pl_bolts\\__init__.py:11: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(numpy, tp_name):\n",
      "C:\\Users\\SToleti\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pl_bolts\\models\\self_supervised\\amdim\\amdim_module.py:34: UnderReviewWarning: The feature generate_power_seq is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  \"lr_options\": generate_power_seq(LEARNING_RATE_CIFAR, 11),\n",
      "C:\\Users\\SToleti\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pl_bolts\\models\\self_supervised\\amdim\\amdim_module.py:92: UnderReviewWarning: The feature FeatureMapContrastiveTask is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  contrastive_task: Union[FeatureMapContrastiveTask] = FeatureMapContrastiveTask(\"01, 02, 11\"),\n",
      "C:\\Users\\SToleti\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pl_bolts\\losses\\self_supervised_learning.py:228: UnderReviewWarning: The feature AmdimNCELoss is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  self.nce_loss = AmdimNCELoss(tclip)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from CustomVAE import VAE\n",
    "from MNISTDataModule import MNISTDataModuleCustom"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba335a4",
   "metadata": {},
   "source": [
    "#### Load Datamodule with dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3c7c411",
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule = MNISTDataModuleCustom()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127d10e6",
   "metadata": {},
   "source": [
    "#### Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff64f4ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 1234\n",
      "D:\\SRT_Courses\\MachineLearning\\TSAI\\Session18\\Part2\\CustomVAE.py:18: UnderReviewWarning: The feature resnet18_encoder is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  self.encoder = resnet18_encoder(False, False)\n",
      "C:\\Users\\SToleti\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pl_bolts\\models\\autoencoders\\components.py:334: UnderReviewWarning: The feature ResNetEncoder is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  return ResNetEncoder(EncoderBlock, [2, 2, 2, 2], first_conv, maxpool1)\n",
      "C:\\Users\\SToleti\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pl_bolts\\models\\autoencoders\\components.py:236: UnderReviewWarning: The feature EncoderBlock is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  layers.append(block(self.inplanes, planes, stride, downsample))\n",
      "C:\\Users\\SToleti\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pl_bolts\\models\\autoencoders\\components.py:56: UnderReviewWarning: The feature conv3x3 is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  self.conv1 = conv3x3(inplanes, planes, stride)\n",
      "C:\\Users\\SToleti\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pl_bolts\\models\\autoencoders\\components.py:231: UnderReviewWarning: The feature conv1x1 is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  conv1x1(self.inplanes, planes * block.expansion, stride),\n",
      "D:\\SRT_Courses\\MachineLearning\\TSAI\\Session18\\Part2\\CustomVAE.py:19: UnderReviewWarning: The feature resnet18_decoder is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  self.decoder = resnet18_decoder(\n",
      "C:\\Users\\SToleti\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pl_bolts\\models\\autoencoders\\components.py:339: UnderReviewWarning: The feature ResNetDecoder is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  return ResNetDecoder(DecoderBlock, [2, 2, 2, 2], latent_dim, input_height, first_conv, maxpool1)\n",
      "C:\\Users\\SToleti\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pl_bolts\\models\\autoencoders\\components.py:301: UnderReviewWarning: The feature resize_conv1x1 is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  resize_conv1x1(self.inplanes, planes * block.expansion, scale),\n",
      "C:\\Users\\SToleti\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pl_bolts\\models\\autoencoders\\components.py:45: UnderReviewWarning: The feature Interpolate is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  return nn.Sequential(Interpolate(scale_factor=scale), conv1x1(in_planes, out_planes))\n",
      "C:\\Users\\SToleti\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pl_bolts\\models\\autoencoders\\components.py:306: UnderReviewWarning: The feature DecoderBlock is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  layers.append(block(self.inplanes, planes, scale, upsample))\n",
      "C:\\Users\\SToleti\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pl_bolts\\models\\autoencoders\\components.py:132: UnderReviewWarning: The feature resize_conv3x3 is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  self.conv1 = resize_conv3x3(inplanes, inplanes)\n",
      "C:\\Users\\SToleti\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=1)` instead.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "C:\\Users\\SToleti\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:106: UserWarning: You passed in a `val_dataloader` but have no `validation_step`. Skipping val loop.\n",
      "  rank_zero_warn(\"You passed in a `val_dataloader` but have no `validation_step`. Skipping val loop.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type          | Params\n",
      "------------------------------------------\n",
      "0 | encoder | ResNetEncoder | 11.2 M\n",
      "1 | decoder | ResNetDecoder | 8.6 M \n",
      "2 | fc_mu   | Linear        | 133 K \n",
      "3 | fc_var  | Linear        | 133 K \n",
      "------------------------------------------\n",
      "20.1 M    Trainable params\n",
      "0         Non-trainable params\n",
      "20.1 M    Total params\n",
      "80.249    Total estimated model params size (MB)\n",
      "C:\\Users\\SToleti\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:224: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|███████████████████████████████████████████████| 938/938 [04:11<00:00,  3.73it/s, loss=2.8e+03, v_num=14]Training loss at end of epoch 0 = 2854.816162109375\n",
      "Epoch 1:   4%|█▉                                             | 39/938 [00:09<03:38,  4.12it/s, loss=2.78e+03, v_num=14]"
     ]
    }
   ],
   "source": [
    "import pytorch_lightning as pl\n",
    "\n",
    "pl.seed_everything(1234)\n",
    "model_vae = VAE()\n",
    "trainer = pl.Trainer(gpus=1, max_epochs=30)\n",
    "trainer.fit(model_vae, datamodule)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2cb812c",
   "metadata": {},
   "source": [
    "#### Plot Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9c0c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "test_dl = datamodule.test_dataloader()\n",
    "for batch in test_dl:\n",
    "    images, label_ohe, label_ohe_random= batch\n",
    "    break  # Break to get the first batch (a batch of images and labels)\n",
    "\n",
    "# Select one image and its corresponding label\n",
    "image = images[0]\n",
    "label_ohe_valid= label_ohe[0]\n",
    "label_ohe_invalid = label_ohe_random[0]\n",
    "\n",
    "label_valid = np.argmax(label_ohe_valid)\n",
    "label_invalid = np.argmax(label_ohe_invalid)\n",
    "\n",
    "\n",
    "# Plot the itest image\n",
    "plt.imshow(image[0], cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title(f\"Actual Image: {label_valid}\")\n",
    "plt.show()\n",
    "image = image.unsqueeze(0)\n",
    "\n",
    "with torch.no_grad():\n",
    "    \n",
    "    # Now pass this image through VAE encoder and plot the decoder output\n",
    "    encoded_image = model_vae.encoder(image.to('cuda'))\n",
    "    combined_features = torch.cat((encoded_image, label_ohe_valid.unsqueeze(0).to('cuda')), dim=1) #get OHE for label features\n",
    "    mu, log_var = model_vae.fc_mu(combined_features), model_vae.fc_var(combined_features)\n",
    "\n",
    "    # sample z from q\n",
    "    std = torch.exp(log_var / 2)\n",
    "    q = torch.distributions.Normal(mu, std)\n",
    "    z = q.rsample()\n",
    "\n",
    "    # decoded \n",
    "    decoded_image = model_vae.decoder(z).to('cpu').detach().numpy()\n",
    "\n",
    "# Plot the generated image with actual label\n",
    "plt.imshow(decoded_image[0,0], cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title(f\"Predicted Image: {label_valid}\")\n",
    "plt.show()\n",
    "\n",
    "decoded_images = []\n",
    "with torch.no_grad():\n",
    "    for i in range(25):   \n",
    "        \n",
    "        # Now pass this image through VAE encoder and plot the decoder output\n",
    "        encoded_image = model_vae.encoder(image.to('cuda'))\n",
    "        combined_features = torch.cat((encoded_image, label_ohe_invalid.unsqueeze(0).to('cuda')), dim=1) #get OHE for label features\n",
    "        mu, log_var = model_vae.fc_mu(combined_features), model_vae.fc_var(combined_features)\n",
    "\n",
    "        # sample z from q\n",
    "        std = torch.exp(log_var / 2)\n",
    "        q = torch.distributions.Normal(mu, std)\n",
    "        z = q.rsample()\n",
    "\n",
    "        # decoded \n",
    "        decoded_image = model_vae.decoder(z).to('cpu').detach().numpy()\n",
    "        decoded_image = decoded_image[0, 0]\n",
    "        decoded_images.append(decoded_image)\n",
    "\n",
    "# Plot the 25 images\n",
    "\n",
    "# Create a 5x5 grid of subplots\n",
    "fig, axes = plt.subplots(5, 5, figsize=(10, 10))\n",
    "\n",
    "# Flatten the axes array so that we can iterate over it easily\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Iterate through the images and plot them in the subplots\n",
    "for i, ax in enumerate(axes):\n",
    "    ax.imshow(decoded_images[i], cmap='gray')  # Replace 'gray' with a colormap of your choice\n",
    "    ax.set_title(f\"Predicted {label_invalid}, trial: {i+1}\")\n",
    "    ax.axis('off')  # Turn off axis labels and ticks\n",
    "\n",
    "# Adjust spacing between subplots\n",
    "plt.subplots_adjust(wspace=0.3, hspace=0.3)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n",
    "\n",
    "       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456264a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

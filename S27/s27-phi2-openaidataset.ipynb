{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30627,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"!pip install -q -U trl transformers accelerate git+https://github.com/huggingface/peft.git\n!pip install -q datasets bitsandbytes einops wandb","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"!pip install -q -U trl transformers accelerate git+https://github.com/huggingface/peft.git\n!pip install -q datasets bitsandbytes einops wandb","metadata":{"execution":{"iopub.status.busy":"2023-12-17T12:49:00.058502Z","iopub.execute_input":"2023-12-17T12:49:00.058894Z","iopub.status.idle":"2023-12-17T12:49:38.115072Z","shell.execute_reply.started":"2023-12-17T12:49:00.058852Z","shell.execute_reply":"2023-12-17T12:49:38.113854Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!pip install --upgrade datasets","metadata":{"execution":{"iopub.status.busy":"2023-12-17T12:51:21.504818Z","iopub.execute_input":"2023-12-17T12:51:21.505740Z","iopub.status.idle":"2023-12-17T12:51:33.388476Z","shell.execute_reply.started":"2023-12-17T12:51:21.505705Z","shell.execute_reply":"2023-12-17T12:51:33.387272Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.15.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.24.3)\nRequirement already satisfied: pyarrow>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (11.0.0)\nRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets) (0.6)\nRequirement already satisfied: dill<0.3.8,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.7)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.0.3)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.31.0)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.66.1)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.15)\nRequirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (2023.10.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.8.5)\nRequirement already satisfied: huggingface-hub>=0.18.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.19.4)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (6.0.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.1.0)\nRequirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (3.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.2)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.18.0->datasets) (3.12.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.18.0->datasets) (4.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.0.9)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2023.11.17)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"from datasets import load_dataset\n\ndataset_name = \"OpenAssistant/oasst1\"\ndataset_ori = load_dataset(dataset_name, split=\"train\")","metadata":{"execution":{"iopub.status.busy":"2023-12-17T12:51:33.390419Z","iopub.execute_input":"2023-12-17T12:51:33.390708Z","iopub.status.idle":"2023-12-17T12:51:36.140105Z","shell.execute_reply.started":"2023-12-17T12:51:33.390683Z","shell.execute_reply":"2023-12-17T12:51:36.139155Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"from datasets import Dataset\n\n# Grouping the texts based on parent id\ngrouped_texts = {}\ncount = 0\nfor item in dataset_ori:\n    parent_id = item['parent_id']\n    text = item['text']\n    role = item['role']\n    \n    if parent_id is None:\n        count = count + 1\n        grouped_texts[count] = ''\n       \n    \n    if role == 'prompter':\n        grouped_texts[count] += f'### Human: {text}'\n    elif role == 'assistant':\n        grouped_texts[count] += f'### Assistant: {text}'\n\n# Creating a new dataset with the grouped texts\ntexts = [v for v in grouped_texts.values()]\n\n# Creating a new dataset with only the 'text' field\ndataset = Dataset.from_dict({'text': texts})\n\n# Print the first element of the new dataset\nprint(dataset[0])","metadata":{"execution":{"iopub.status.busy":"2023-12-17T12:51:36.141347Z","iopub.execute_input":"2023-12-17T12:51:36.141856Z","iopub.status.idle":"2023-12-17T12:52:02.562730Z","shell.execute_reply.started":"2023-12-17T12:51:36.141826Z","shell.execute_reply":"2023-12-17T12:52:02.561709Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"{'text': '### Human: Can you write a short introduction about the relevance of the term \"monopsony\" in economics? Please use examples related to potential monopsonies in the labour market and cite relevant research.### Assistant: \"Monopsony\" refers to a market structure where there is only one buyer for a particular good or service. In economics, this term is particularly relevant in the labor market, where a monopsony employer has significant power over the wages and working conditions of their employees. The presence of a monopsony can result in lower wages and reduced employment opportunities for workers, as the employer has little incentive to increase wages or provide better working conditions.\\n\\nRecent research has identified potential monopsonies in industries such as retail and fast food, where a few large companies control a significant portion of the market (Bivens & Mishel, 2013). In these industries, workers often face low wages, limited benefits, and reduced bargaining power, leading to a situation where they are dependent on the employer for their livelihood. This dependence can result in further suppression of wages and a decline in working conditions.\\n\\nOverall, the concept of monopsony is essential to understanding the dynamics of labor markets and the impact of market power on workers. Further research is needed to understand the extent and impact of monopsonies on the economy and to develop policies to address this issue.\\n\\nReferences:\\nBivens, J., & Mishel, L. (2013). The Pay of Corporate Executives and Financial Professionals as Evidence of Rents in Top 1 Percent Incomes. Journal of Economic Perspectives, 27(3), 57-78.### Human: Now explain it to a dog### Assistant: Monopsony is a market structure in which there is a single buyer in a market. In the context of labor markets, a monopsony occurs when there is only one employer in a particular industry or geographic area, giving that employer significant power over the wages and working conditions of workers. This results in a situation where the employer has the ability to suppress wages and reduce the bargaining power of workers.\\n\\nResearch has shown that the existence of monopsony power in labor markets can have negative effects on workers, such as lower wages, reduced benefits, and limited job opportunities. For example, a study by Autor, Dorn, and Hanson (2013) found evidence of monopsony power in certain U.S. labor markets, resulting in lower wages and reduced job opportunities for workers. Similarly, another study by Bharadwaj, Black, and Kolesnikova (2019) found that the presence of a single dominant employer in a local labor market was associated with lower wages for workers.### Human: How can one fight back when a monospony had been created?### Assistant: Monopsony refers to a market structure where there is only one buyer of a good or service. In the context of labor markets, a monopsony occurs when there is only one employer in a particular geographic area or industry, giving them significant power to set wages and working conditions. Research has shown that the existence of monopsonies can lead to lower wages and reduced job opportunities for workers. For example, a study by the National Bureau of Economic Research found that in industries with high levels of concentration, workers earn lower wages and are less likely to receive benefits such as health insurance.### Human: What can be done at a regulatory level to ensure, in a monopsony, that the power over the employees isn\\'t abused? List a few options and focus on the organs that should act.### Assistant: Here are some potential regulatory options to address monopsony power over employees:\\n\\n- Antitrust enforcement agencies like the FTC or DOJ could investigate and take action against dominant employers that are abusing their market power to suppress wages or worsen working conditions. They could force divestitures or other structural remedies.\\n- Labor standards agencies could set industry-specific minimum wage floors or other regulations around compensation and working conditions. This would reduce the ability of dominant employers to push wages/conditions below certain thresholds.\\n- Sector-specific regulators could impose requirements around how companies hire, compensate, and treat workers. For example, banking regulators could prohibit abusive practices by dominant banks with regard to their employees.\\n- Legislatures could pass laws### Assistant: Regulatory intervention can be used to address the negative consequences of monopsony power in the labor market. A few options include:\\n\\n1. Antitrust enforcement: Antitrust laws can be used to prevent firms from engaging in practices that limit competition and suppress wages. The antitrust division of the Department of Justice and the Federal Trade Commission (FTC) are responsible for enforcing these laws.\\n\\n2. Labor standards and protections: Governments can set minimum wage standards and other labor protections to ensure that workers are paid a fair wage, even in industries dominated by a single buyer. The U.S. Department of Labor is responsible for enforcing these standards.\\n\\n3. Occupational licensing reform: Occupational licensing requirements can restrict worker mobility and increase the bargaining power of employers. Reforms to licensing requirements can reduce these barriers and increase competition in the labor market. State governments typically regulate occupational licensing.\\n\\n4. Collective bargaining rights: Collective bargaining by workers can increase their bargaining power and lead to higher wages. Governments can protect and promote collective bargaining rights to counteract the effects of monopsony power. The National Labor Relations Board is responsible for enforcing workers\\' rights to engage in collective bargaining in the U.S.\\n\\nThese are just a few examples of regulatory options that can be used to address monopsony power in the labor market. The specific actions taken will depend on the particular circumstances and context of each case.### Assistant: Yes, that\\'s correct. Keeping the code for the TESR and the registration code in the same file can make it easier to manage and maintain the code. The ExampleMod class acts as a container for the TESR code, providing a convenient and logical grouping. The functionality of the code remains unchanged, and the TESR will still be properly registered and used to render the custom tile entities in the game.### Human: I would imagine this is similar or even the same as a \"monopoly\" but I am not sure.\\n\\nAssuming that this some kind of \"final state\" of a particular industry or even an entire economy, give me some larger historical examples of this kind of structure consolidating over time, and describe what circumstances are common prerequisite.### Assistant: Bouguereau died in 1905, so it is unlikely that any of his direct descendants are still alive. However, his works continue to be popular and are sold at auction and through art dealers. It is possible that some indirect descendants may benefit from the sale of his works.'}\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nfrom transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, AutoTokenizer\n\nmodel_name = \"microsoft/phi-2\"\n\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_compute_dtype=torch.float16,\n)\n\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_name,\n    quantization_config=bnb_config,\n    trust_remote_code=True\n)\nmodel.config.use_cache = False","metadata":{"execution":{"iopub.status.busy":"2023-12-17T12:52:02.565176Z","iopub.execute_input":"2023-12-17T12:52:02.565503Z","iopub.status.idle":"2023-12-17T12:52:10.054144Z","shell.execute_reply.started":"2023-12-17T12:52:02.565475Z","shell.execute_reply":"2023-12-17T12:52:10.053320Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6a51f1337a104c5a974cebd5557848d1"}},"metadata":{}}]},{"cell_type":"code","source":"print(model)","metadata":{"execution":{"iopub.status.busy":"2023-12-17T12:52:10.055302Z","iopub.execute_input":"2023-12-17T12:52:10.055783Z","iopub.status.idle":"2023-12-17T12:52:10.063438Z","shell.execute_reply.started":"2023-12-17T12:52:10.055755Z","shell.execute_reply":"2023-12-17T12:52:10.062425Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"PhiForCausalLM(\n  (transformer): PhiModel(\n    (embd): Embedding(\n      (wte): Embedding(51200, 2560)\n      (drop): Dropout(p=0.0, inplace=False)\n    )\n    (h): ModuleList(\n      (0-31): 32 x ParallelBlock(\n        (ln): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n        (resid_dropout): Dropout(p=0.1, inplace=False)\n        (mixer): MHA(\n          (rotary_emb): RotaryEmbedding()\n          (Wqkv): Linear4bit(in_features=2560, out_features=7680, bias=True)\n          (out_proj): Linear4bit(in_features=2560, out_features=2560, bias=True)\n          (inner_attn): SelfAttention(\n            (drop): Dropout(p=0.0, inplace=False)\n          )\n          (inner_cross_attn): CrossAttention(\n            (drop): Dropout(p=0.0, inplace=False)\n          )\n        )\n        (mlp): MLP(\n          (fc1): Linear4bit(in_features=2560, out_features=10240, bias=True)\n          (fc2): Linear4bit(in_features=10240, out_features=2560, bias=True)\n          (act): NewGELUActivation()\n        )\n      )\n    )\n  )\n  (lm_head): CausalLMHead(\n    (ln): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n    (linear): Linear(in_features=2560, out_features=51200, bias=True)\n  )\n  (loss): CausalLMLoss(\n    (loss_fct): CrossEntropyLoss()\n  )\n)\n","output_type":"stream"}]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\ntokenizer.pad_token = tokenizer.eos_token","metadata":{"execution":{"iopub.status.busy":"2023-12-17T12:52:10.064477Z","iopub.execute_input":"2023-12-17T12:52:10.064759Z","iopub.status.idle":"2023-12-17T12:52:10.262995Z","shell.execute_reply.started":"2023-12-17T12:52:10.064735Z","shell.execute_reply":"2023-12-17T12:52:10.262023Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"}]},{"cell_type":"code","source":"from peft import LoraConfig\n\nlora_alpha = 16\nlora_dropout = 0.1\nlora_r = 64\n\npeft_config = LoraConfig(\n    lora_alpha=lora_alpha,\n    lora_dropout=lora_dropout,\n    r=lora_r,\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\",\n    target_modules=[\n        \"Wqkv\",\n        \"out_proj\",\n        \"fc1\",\n        \"fc2\",\n    ]\n)","metadata":{"execution":{"iopub.status.busy":"2023-12-17T12:52:10.264136Z","iopub.execute_input":"2023-12-17T12:52:10.264419Z","iopub.status.idle":"2023-12-17T12:52:10.304314Z","shell.execute_reply.started":"2023-12-17T12:52:10.264385Z","shell.execute_reply":"2023-12-17T12:52:10.303612Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"from transformers import TrainingArguments\n\noutput_dir = \"./results\"\nper_device_train_batch_size = 2\ngradient_accumulation_steps = 8\noptim = \"paged_adamw_32bit\"\nsave_steps = 100\nlogging_steps = 10\nlearning_rate = 2e-4\nmax_grad_norm = 0.3\nmax_steps = 500\nwarmup_ratio = 0.03\nlr_scheduler_type = \"constant\"\n\ntraining_arguments = TrainingArguments(\n    output_dir=output_dir,\n    per_device_train_batch_size=per_device_train_batch_size,\n    gradient_accumulation_steps=gradient_accumulation_steps,\n    optim=optim,\n    save_steps=save_steps,\n    logging_steps=logging_steps,\n    learning_rate=learning_rate,\n    fp16=True,\n    max_grad_norm=max_grad_norm,\n    max_steps=max_steps,\n    warmup_ratio=warmup_ratio,\n    group_by_length=True,\n    lr_scheduler_type=lr_scheduler_type,\n    #gradient_checkpointing=True,\n)","metadata":{"execution":{"iopub.status.busy":"2023-12-17T12:52:10.306247Z","iopub.execute_input":"2023-12-17T12:52:10.306791Z","iopub.status.idle":"2023-12-17T12:52:10.329678Z","shell.execute_reply.started":"2023-12-17T12:52:10.306763Z","shell.execute_reply":"2023-12-17T12:52:10.328985Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"from trl import SFTTrainer\n\nmax_seq_length = 256\n\ntrainer = SFTTrainer(\n    model=model,\n    train_dataset=dataset,\n    peft_config=peft_config,\n    dataset_text_field=\"text\",\n    max_seq_length=max_seq_length,\n    tokenizer=tokenizer,\n    args=training_arguments,\n)","metadata":{"execution":{"iopub.status.busy":"2023-12-17T12:52:10.330623Z","iopub.execute_input":"2023-12-17T12:52:10.330889Z","iopub.status.idle":"2023-12-17T12:52:30.657932Z","shell.execute_reply.started":"2023-12-17T12:52:10.330865Z","shell.execute_reply":"2023-12-17T12:52:30.657170Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_config.py:141: UserWarning: The `optimize_cuda_cache` arguement will be deprecated soon, please use `optimize_device_cache` instead.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/9846 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"688fe22fcd48455b9a93a2ac170c86eb"}},"metadata":{}}]},{"cell_type":"code","source":"for name, module in trainer.model.named_modules():\n    if \"norm\" in name:\n        module = module.to(torch.float32)","metadata":{"execution":{"iopub.status.busy":"2023-12-17T12:53:15.175368Z","iopub.execute_input":"2023-12-17T12:53:15.175757Z","iopub.status.idle":"2023-12-17T12:53:15.185030Z","shell.execute_reply.started":"2023-12-17T12:53:15.175725Z","shell.execute_reply":"2023-12-17T12:53:15.184114Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2023-12-17T12:53:18.990193Z","iopub.execute_input":"2023-12-17T12:53:18.990553Z","iopub.status.idle":"2023-12-17T14:17:32.445685Z","shell.execute_reply.started":"2023-12-17T12:53:18.990526Z","shell.execute_reply":"2023-12-17T14:17:32.444755Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msriramya-toleti\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20231217_125325-3hqke20p</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/sriramya-toleti/huggingface/runs/3hqke20p' target=\"_blank\">light-music-4</a></strong> to <a href='https://wandb.ai/sriramya-toleti/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/sriramya-toleti/huggingface' target=\"_blank\">https://wandb.ai/sriramya-toleti/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/sriramya-toleti/huggingface/runs/3hqke20p' target=\"_blank\">https://wandb.ai/sriramya-toleti/huggingface/runs/3hqke20p</a>"},"metadata":{}},{"name":"stderr","text":"You're using a CodeGenTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [500/500 1:23:25, Epoch 0/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>10</td>\n      <td>1.870700</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>1.791800</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>1.741000</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>1.685900</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>1.798200</td>\n    </tr>\n    <tr>\n      <td>60</td>\n      <td>1.744900</td>\n    </tr>\n    <tr>\n      <td>70</td>\n      <td>1.735000</td>\n    </tr>\n    <tr>\n      <td>80</td>\n      <td>1.649700</td>\n    </tr>\n    <tr>\n      <td>90</td>\n      <td>1.716900</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>1.792200</td>\n    </tr>\n    <tr>\n      <td>110</td>\n      <td>1.723300</td>\n    </tr>\n    <tr>\n      <td>120</td>\n      <td>1.646400</td>\n    </tr>\n    <tr>\n      <td>130</td>\n      <td>1.756800</td>\n    </tr>\n    <tr>\n      <td>140</td>\n      <td>1.712400</td>\n    </tr>\n    <tr>\n      <td>150</td>\n      <td>1.776800</td>\n    </tr>\n    <tr>\n      <td>160</td>\n      <td>1.748500</td>\n    </tr>\n    <tr>\n      <td>170</td>\n      <td>1.673900</td>\n    </tr>\n    <tr>\n      <td>180</td>\n      <td>1.638600</td>\n    </tr>\n    <tr>\n      <td>190</td>\n      <td>1.752900</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>1.762400</td>\n    </tr>\n    <tr>\n      <td>210</td>\n      <td>1.730300</td>\n    </tr>\n    <tr>\n      <td>220</td>\n      <td>1.632600</td>\n    </tr>\n    <tr>\n      <td>230</td>\n      <td>1.663700</td>\n    </tr>\n    <tr>\n      <td>240</td>\n      <td>1.688300</td>\n    </tr>\n    <tr>\n      <td>250</td>\n      <td>1.760800</td>\n    </tr>\n    <tr>\n      <td>260</td>\n      <td>1.698600</td>\n    </tr>\n    <tr>\n      <td>270</td>\n      <td>1.605400</td>\n    </tr>\n    <tr>\n      <td>280</td>\n      <td>1.678500</td>\n    </tr>\n    <tr>\n      <td>290</td>\n      <td>1.630800</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>1.884000</td>\n    </tr>\n    <tr>\n      <td>310</td>\n      <td>1.689900</td>\n    </tr>\n    <tr>\n      <td>320</td>\n      <td>1.704300</td>\n    </tr>\n    <tr>\n      <td>330</td>\n      <td>1.641300</td>\n    </tr>\n    <tr>\n      <td>340</td>\n      <td>1.736500</td>\n    </tr>\n    <tr>\n      <td>350</td>\n      <td>1.676000</td>\n    </tr>\n    <tr>\n      <td>360</td>\n      <td>1.673800</td>\n    </tr>\n    <tr>\n      <td>370</td>\n      <td>1.717500</td>\n    </tr>\n    <tr>\n      <td>380</td>\n      <td>1.614300</td>\n    </tr>\n    <tr>\n      <td>390</td>\n      <td>1.648100</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>1.856600</td>\n    </tr>\n    <tr>\n      <td>410</td>\n      <td>1.741000</td>\n    </tr>\n    <tr>\n      <td>420</td>\n      <td>1.696400</td>\n    </tr>\n    <tr>\n      <td>430</td>\n      <td>1.621100</td>\n    </tr>\n    <tr>\n      <td>440</td>\n      <td>1.642500</td>\n    </tr>\n    <tr>\n      <td>450</td>\n      <td>1.759500</td>\n    </tr>\n    <tr>\n      <td>460</td>\n      <td>1.600000</td>\n    </tr>\n    <tr>\n      <td>470</td>\n      <td>1.606000</td>\n    </tr>\n    <tr>\n      <td>480</td>\n      <td>1.664900</td>\n    </tr>\n    <tr>\n      <td>490</td>\n      <td>1.644700</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>1.763400</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=500, training_loss=1.7077879753112792, metrics={'train_runtime': 5049.567, 'train_samples_per_second': 1.584, 'train_steps_per_second': 0.099, 'total_flos': 3.293667738832896e+16, 'train_loss': 1.7077879753112792, 'epoch': 0.81})"},"metadata":{}}]},{"cell_type":"code","source":"from transformers import (\n    AutoModelForCausalLM,\n    AutoTokenizer,\n    BitsAndBytesConfig,\n    HfArgumentParser,\n    TrainingArguments,\n    pipeline,\n    logging,\n)","metadata":{"execution":{"iopub.status.busy":"2023-12-17T14:17:49.406097Z","iopub.execute_input":"2023-12-17T14:17:49.406961Z","iopub.status.idle":"2023-12-17T14:17:50.165768Z","shell.execute_reply.started":"2023-12-17T14:17:49.406925Z","shell.execute_reply":"2023-12-17T14:17:50.164631Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# Run text generation pipeline with our next model\nprompt = \"What is a large language model?\"\npipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, max_length=200)\nresult = pipe(f\"<s>[INST] {prompt} [/INST]\")\nprint(result[0]['generated_text'])","metadata":{"execution":{"iopub.status.busy":"2023-12-17T14:17:53.974800Z","iopub.execute_input":"2023-12-17T14:17:53.975481Z","iopub.status.idle":"2023-12-17T14:18:09.497599Z","shell.execute_reply.started":"2023-12-17T14:17:53.975448Z","shell.execute_reply":"2023-12-17T14:18:09.496423Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1518: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use and modify the model generation configuration (see https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"<s>[INST] What is a large language model? [/INST]>\n<s>[INST] What is a large language model? [/INST]>\n<s>[INST] What is a large language model? [/INST]>\n<s>[INST] What is a large language model? [/INST]>\n<s>[INST] What is a large language model? [/INST]>\n<s>[INST] What is a large language model? [/INST]>\n<s>[INST] What is a large language model? [/INST]>\n<s>[INST] What is a large language model? [/INST]>\n<s>[INST] What is a large language model? [/INST]>\n<s>[INST] What is a large language model? [/INST]>\n<s>[INST] What is a large language model? [/INST]>\n<s>[INST] What is a large language model? [/\n","output_type":"stream"}]}]}
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "source": [
    "!cd /kaggle/working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-31T10:38:24.081819Z",
     "iopub.status.busy": "2023-08-31T10:38:24.080928Z",
     "iopub.status.idle": "2023-08-31T10:38:29.218849Z",
     "shell.execute_reply": "2023-08-31T10:38:29.217683Z",
     "shell.execute_reply.started": "2023-08-31T10:38:24.081784Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed 'TSAI_ERA_Assignments/S11/S11.ipynb'\n",
      "removed 'TSAI_ERA_Assignments/S11/README.md'\n",
      "removed 'TSAI_ERA_Assignments/S11/Results_GradCAM.jpg'\n",
      "removed 'TSAI_ERA_Assignments/S11/utils.py'\n",
      "removed 'TSAI_ERA_Assignments/S11/models/custom_resnet.py'\n",
      "removed 'TSAI_ERA_Assignments/S11/models/resnet.py'\n",
      "removed directory 'TSAI_ERA_Assignments/S11/models'\n",
      "removed directory 'TSAI_ERA_Assignments/S11'\n",
      "removed 'TSAI_ERA_Assignments/S12/custom_resnet.py'\n",
      "removed 'TSAI_ERA_Assignments/S12/S12.ipynb'\n",
      "removed 'TSAI_ERA_Assignments/S12/README.md'\n",
      "removed 'TSAI_ERA_Assignments/S12/utils.py'\n",
      "removed directory 'TSAI_ERA_Assignments/S12'\n",
      "removed 'TSAI_ERA_Assignments/S13/train.py'\n",
      "removed 'TSAI_ERA_Assignments/S13/LightningModel.py'\n",
      "removed 'TSAI_ERA_Assignments/S13/loss.py'\n",
      "removed 'TSAI_ERA_Assignments/S13/loss_1_1.py'\n",
      "removed 'TSAI_ERA_Assignments/S13/README.md'\n",
      "removed 'TSAI_ERA_Assignments/S13/dataset_org.py'\n",
      "removed 'TSAI_ERA_Assignments/S13/S13.ipynb'\n",
      "removed 'TSAI_ERA_Assignments/S13/dataset.py'\n",
      "removed 'TSAI_ERA_Assignments/S13/utils.py'\n",
      "removed 'TSAI_ERA_Assignments/S13/dataloader.ipynb'\n",
      "removed 'TSAI_ERA_Assignments/S13/model.py'\n",
      "removed 'TSAI_ERA_Assignments/S13/config.py'\n",
      "removed 'TSAI_ERA_Assignments/S13/image.png'\n",
      "removed directory 'TSAI_ERA_Assignments/S13'\n",
      "removed 'TSAI_ERA_Assignments/S16/train.py'\n",
      "removed 'TSAI_ERA_Assignments/S16/train.ipynb'\n",
      "removed 'TSAI_ERA_Assignments/S16/dataset.py'\n",
      "removed 'TSAI_ERA_Assignments/S16/model.py'\n",
      "removed 'TSAI_ERA_Assignments/S16/config.py'\n",
      "removed directory 'TSAI_ERA_Assignments/S16'\n",
      "removed 'TSAI_ERA_Assignments/S10/custom_resnet.py'\n",
      "removed 'TSAI_ERA_Assignments/S10/README.md'\n",
      "removed 'TSAI_ERA_Assignments/S10/utils.py'\n",
      "removed 'TSAI_ERA_Assignments/S10/S10.ipynb'\n",
      "removed directory 'TSAI_ERA_Assignments/S10'\n",
      "removed 'TSAI_ERA_Assignments/KaggleTrial.ipynb'\n",
      "removed 'TSAI_ERA_Assignments/S6/README.md'\n",
      "removed 'TSAI_ERA_Assignments/S6/BackPropogation/BackPropogationCalculationTable.jpg'\n",
      "removed 'TSAI_ERA_Assignments/S6/BackPropogation/LearningRate_0.8.jpg'\n",
      "removed 'TSAI_ERA_Assignments/S6/BackPropogation/LearningRate_1000.jpg'\n",
      "removed 'TSAI_ERA_Assignments/S6/BackPropogation/LearningRate_2.0.jpg'\n",
      "removed 'TSAI_ERA_Assignments/S6/BackPropogation/README.md'\n",
      "removed 'TSAI_ERA_Assignments/S6/BackPropogation/NetworkAndFormulae.jpg'\n",
      "removed 'TSAI_ERA_Assignments/S6/BackPropogation/Network.jpg'\n",
      "removed 'TSAI_ERA_Assignments/S6/BackPropogation/LearningRate_0.1.jpg'\n",
      "removed 'TSAI_ERA_Assignments/S6/BackPropogation/LearningRate_1.0.jpg'\n",
      "removed 'TSAI_ERA_Assignments/S6/BackPropogation/LearningRate_0.5.jpg'\n",
      "removed 'TSAI_ERA_Assignments/S6/BackPropogation/BackPropagation.xlsx'\n",
      "removed 'TSAI_ERA_Assignments/S6/BackPropogation/LearningRate_0.2.jpg'\n",
      "removed directory 'TSAI_ERA_Assignments/S6/BackPropogation'\n",
      "removed 'TSAI_ERA_Assignments/S6/S6.ipynb'\n",
      "removed 'TSAI_ERA_Assignments/S6/utils.py'\n",
      "removed 'TSAI_ERA_Assignments/S6/model.py'\n",
      "removed directory 'TSAI_ERA_Assignments/S6'\n",
      "removed 'TSAI_ERA_Assignments/README.md'\n",
      "removed 'TSAI_ERA_Assignments/.git/packed-refs'\n",
      "removed 'TSAI_ERA_Assignments/.git/refs/remotes/origin/HEAD'\n",
      "removed directory 'TSAI_ERA_Assignments/.git/refs/remotes/origin'\n",
      "removed directory 'TSAI_ERA_Assignments/.git/refs/remotes'\n",
      "removed 'TSAI_ERA_Assignments/.git/refs/heads/main'\n",
      "removed directory 'TSAI_ERA_Assignments/.git/refs/heads'\n",
      "removed directory 'TSAI_ERA_Assignments/.git/refs'\n",
      "removed 'TSAI_ERA_Assignments/.git/logs/refs/remotes/origin/HEAD'\n",
      "removed directory 'TSAI_ERA_Assignments/.git/logs/refs/remotes/origin'\n",
      "removed directory 'TSAI_ERA_Assignments/.git/logs/refs/remotes'\n",
      "removed 'TSAI_ERA_Assignments/.git/logs/refs/heads/main'\n",
      "removed directory 'TSAI_ERA_Assignments/.git/logs/refs/heads'\n",
      "removed directory 'TSAI_ERA_Assignments/.git/logs/refs'\n",
      "removed 'TSAI_ERA_Assignments/.git/logs/HEAD'\n",
      "removed directory 'TSAI_ERA_Assignments/.git/logs'\n",
      "removed 'TSAI_ERA_Assignments/.git/HEAD'\n",
      "removed 'TSAI_ERA_Assignments/.git/info/exclude'\n",
      "removed directory 'TSAI_ERA_Assignments/.git/info'\n",
      "removed 'TSAI_ERA_Assignments/.git/index'\n",
      "removed 'TSAI_ERA_Assignments/.git/description'\n",
      "removed 'TSAI_ERA_Assignments/.git/config'\n",
      "removed 'TSAI_ERA_Assignments/.git/hooks/commit-msg.sample'\n",
      "removed 'TSAI_ERA_Assignments/.git/hooks/push-to-checkout.sample'\n",
      "removed 'TSAI_ERA_Assignments/.git/hooks/pre-push.sample'\n",
      "removed 'TSAI_ERA_Assignments/.git/hooks/pre-rebase.sample'\n",
      "removed 'TSAI_ERA_Assignments/.git/hooks/fsmonitor-watchman.sample'\n",
      "removed 'TSAI_ERA_Assignments/.git/hooks/applypatch-msg.sample'\n",
      "removed 'TSAI_ERA_Assignments/.git/hooks/pre-receive.sample'\n",
      "removed 'TSAI_ERA_Assignments/.git/hooks/update.sample'\n",
      "removed 'TSAI_ERA_Assignments/.git/hooks/pre-applypatch.sample'\n",
      "removed 'TSAI_ERA_Assignments/.git/hooks/pre-commit.sample'\n",
      "removed 'TSAI_ERA_Assignments/.git/hooks/post-update.sample'\n",
      "removed 'TSAI_ERA_Assignments/.git/hooks/pre-merge-commit.sample'\n",
      "removed 'TSAI_ERA_Assignments/.git/hooks/prepare-commit-msg.sample'\n",
      "removed directory 'TSAI_ERA_Assignments/.git/hooks'\n",
      "removed 'TSAI_ERA_Assignments/.git/objects/pack/pack-4c359ae98bfb6150378ab8986253f116d325a571.pack'\n",
      "removed 'TSAI_ERA_Assignments/.git/objects/pack/pack-4c359ae98bfb6150378ab8986253f116d325a571.idx'\n",
      "removed directory 'TSAI_ERA_Assignments/.git/objects/pack'\n",
      "removed directory 'TSAI_ERA_Assignments/.git/objects'\n",
      "removed directory 'TSAI_ERA_Assignments/.git'\n",
      "removed 'TSAI_ERA_Assignments/S15/runs/tmodel/events.out.tfevents.1693125237.18289281f171.28.0'\n",
      "removed directory 'TSAI_ERA_Assignments/S15/runs/tmodel'\n",
      "removed directory 'TSAI_ERA_Assignments/S15/runs'\n",
      "removed 'TSAI_ERA_Assignments/S15/tokenizer_en.json'\n",
      "removed 'TSAI_ERA_Assignments/S15/LightningModel.py'\n",
      "removed 'TSAI_ERA_Assignments/S15/lightning_logs/version_0/checkpoints/epoch=7-step=38800.ckpt'\n",
      "removed directory 'TSAI_ERA_Assignments/S15/lightning_logs/version_0/checkpoints'\n",
      "removed 'TSAI_ERA_Assignments/S15/lightning_logs/version_0/hparams.yaml'\n",
      "removed 'TSAI_ERA_Assignments/S15/lightning_logs/version_0/events.out.tfevents.1693125265.18289281f171.28.1'\n",
      "removed directory 'TSAI_ERA_Assignments/S15/lightning_logs/version_0'\n",
      "removed directory 'TSAI_ERA_Assignments/S15/lightning_logs'\n",
      "removed 'TSAI_ERA_Assignments/S15/__pycache__/dataset.cpython-310.pyc'\n",
      "removed 'TSAI_ERA_Assignments/S15/__pycache__/config.cpython-310.pyc'\n",
      "removed 'TSAI_ERA_Assignments/S15/__pycache__/LightningModel.cpython-310.pyc'\n",
      "removed 'TSAI_ERA_Assignments/S15/__pycache__/model.cpython-310.pyc'\n",
      "removed directory 'TSAI_ERA_Assignments/S15/__pycache__'\n",
      "removed 'TSAI_ERA_Assignments/S15/weights/tmodel_06.pt'\n",
      "removed 'TSAI_ERA_Assignments/S15/weights/tmodel_00.pt'\n",
      "removed 'TSAI_ERA_Assignments/S15/weights/tmodel_05.pt'\n",
      "removed 'TSAI_ERA_Assignments/S15/weights/tmodel_02.pt'\n",
      "removed 'TSAI_ERA_Assignments/S15/weights/tmodel_07.pt'\n",
      "removed 'TSAI_ERA_Assignments/S15/weights/tmodel_04.pt'\n",
      "removed 'TSAI_ERA_Assignments/S15/weights/tmodel_01.pt'\n",
      "removed 'TSAI_ERA_Assignments/S15/weights/tmodel_03.pt'\n",
      "removed directory 'TSAI_ERA_Assignments/S15/weights'\n",
      "removed 'TSAI_ERA_Assignments/S15/tokenizer_it.json'\n",
      "removed 'TSAI_ERA_Assignments/S15/dataset.py'\n",
      "removed 'TSAI_ERA_Assignments/S15/S15.ipynb'\n",
      "removed 'TSAI_ERA_Assignments/S15/model.py'\n",
      "removed 'TSAI_ERA_Assignments/S15/config.py'\n",
      "removed directory 'TSAI_ERA_Assignments/S15'\n",
      "removed 'TSAI_ERA_Assignments/S7/Code4.ipynb'\n",
      "removed 'TSAI_ERA_Assignments/S7/Code3.ipynb'\n",
      "removed 'TSAI_ERA_Assignments/S7/Code9.ipynb'\n",
      "removed 'TSAI_ERA_Assignments/S7/Code8WithDataAugmentation.ipynb'\n",
      "removed 'TSAI_ERA_Assignments/S7/README.md'\n",
      "removed 'TSAI_ERA_Assignments/S7/Code8.ipynb'\n",
      "removed 'TSAI_ERA_Assignments/S7/Code5.ipynb'\n",
      "removed 'TSAI_ERA_Assignments/S7/Code1.ipynb'\n",
      "removed 'TSAI_ERA_Assignments/S7/utils.py'\n",
      "removed 'TSAI_ERA_Assignments/S7/Code6.ipynb'\n",
      "removed 'TSAI_ERA_Assignments/S7/models/model_3.py'\n",
      "removed 'TSAI_ERA_Assignments/S7/models/model_4.py'\n",
      "removed 'TSAI_ERA_Assignments/S7/models/model_1.py'\n",
      "removed 'TSAI_ERA_Assignments/S7/models/model_8.py'\n",
      "removed 'TSAI_ERA_Assignments/S7/models/model_6.py'\n",
      "removed 'TSAI_ERA_Assignments/S7/models/model_5.py'\n",
      "removed 'TSAI_ERA_Assignments/S7/models/model_7.py'\n",
      "removed 'TSAI_ERA_Assignments/S7/models/model_2.py'\n",
      "removed 'TSAI_ERA_Assignments/S7/models/model_9.py'\n",
      "removed directory 'TSAI_ERA_Assignments/S7/models'\n",
      "removed 'TSAI_ERA_Assignments/S7/Code2.ipynb'\n",
      "removed 'TSAI_ERA_Assignments/S7/Code7.ipynb'\n",
      "removed directory 'TSAI_ERA_Assignments/S7'\n",
      "removed 'TSAI_ERA_Assignments/S9/README.md'\n",
      "removed 'TSAI_ERA_Assignments/S9/S9.ipynb'\n",
      "removed 'TSAI_ERA_Assignments/S9/utils.py'\n",
      "removed 'TSAI_ERA_Assignments/S9/model.py'\n",
      "removed directory 'TSAI_ERA_Assignments/S9'\n",
      "removed directory 'TSAI_ERA_Assignments'\n",
      "Cloning into 'TSAI_ERA_Assignments'...\n",
      "remote: Enumerating objects: 423, done.\u001b[K\n",
      "remote: Counting objects: 100% (228/228), done.\u001b[K\n",
      "remote: Compressing objects: 100% (87/87), done.\u001b[K\n",
      "remote: Total 423 (delta 152), reused 212 (delta 141), pack-reused 195\u001b[K\n",
      "Receiving objects: 100% (423/423), 10.44 MiB | 19.48 MiB/s, done.\n",
      "Resolving deltas: 100% (226/226), done.\n"
     ]
    }
   ],
   "source": [
    "!rm -vrf TSAI_ERA_Assignments\n",
    "!git clone https://github.com/ToletiSri/TSAI_ERA_Assignments.git\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-31T10:38:29.223325Z",
     "iopub.status.busy": "2023-08-31T10:38:29.222980Z",
     "iopub.status.idle": "2023-08-31T10:38:29.236430Z",
     "shell.execute_reply": "2023-08-31T10:38:29.235425Z",
     "shell.execute_reply.started": "2023-08-31T10:38:29.223292Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/TSAI_ERA_Assignments/S15\n"
     ]
    }
   ],
   "source": [
    "cd TSAI_ERA_Assignments/S15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-31T10:38:29.239766Z",
     "iopub.status.busy": "2023-08-31T10:38:29.239078Z",
     "iopub.status.idle": "2023-08-31T10:38:29.265758Z",
     "shell.execute_reply": "2023-08-31T10:38:29.264770Z",
     "shell.execute_reply.started": "2023-08-31T10:38:29.239732Z"
    }
   },
   "outputs": [],
   "source": [
    "from config import get_config\n",
    "cfg = get_config()\n",
    "cfg['batch_size'] = 6\n",
    "cfg['preload'] = None\n",
    "cfg['num_epochs'] = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-31T10:38:29.268981Z",
     "iopub.status.busy": "2023-08-31T10:38:29.268311Z",
     "iopub.status.idle": "2023-08-31T10:38:44.765729Z",
     "shell.execute_reply": "2023-08-31T10:38:44.764764Z",
     "shell.execute_reply.started": "2023-08-31T10:38:29.268948Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n",
      "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n",
      "  warnings.warn(f\"file system plugins are not loaded: {e}\")\n",
      "stty: 'standard input': Inappropriate ioctl for device\n"
     ]
    }
   ],
   "source": [
    "import LightningModel\n",
    "from pytorch_lightning import LightningModule\n",
    "\n",
    "myLitmodel = LightningModel.LitTransformer(cfg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-31T10:38:44.767436Z",
     "iopub.status.busy": "2023-08-31T10:38:44.766853Z",
     "iopub.status.idle": "2023-08-31T15:08:43.146880Z",
     "shell.execute_reply": "2023-08-31T15:08:43.144060Z",
     "shell.execute_reply.started": "2023-08-31T10:38:44.767402Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/lightning_fabric/connector.py:555: UserWarning: 16 is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b992193f9acb4e22bb07590868dac1f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/2.40k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d0f333022134414b99dd90fc5920725",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading metadata:   0%|          | 0.00/7.98k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset opus_books/en-it (download: 3.14 MiB, generated: 8.58 MiB, post-processed: Unknown size, total: 11.72 MiB) to /root/.cache/huggingface/datasets/opus_books/en-it/1.0.0/e8f950a4f32dc39b7f9088908216cd2d7e21ac35f893d04d39eb594746af2daf...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d28f3390e1e4a658ab628246c4b0f81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/3.30M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/32332 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset opus_books downloaded and prepared to /root/.cache/huggingface/datasets/opus_books/en-it/1.0.0/e8f950a4f32dc39b7f9088908216cd2d7e21ac35f893d04d39eb594746af2daf. Subsequent calls will reuse this data.\n",
      "Max length of source sentence: 309\n",
      "Max length of target sentence: 274\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "--------------------------------------------------------------------------------\n",
      "    SOURCE: 'Oh no, I shall not be ready myself,' she said, and immediately thought: 'So it was possible to arrange things as I wished!' – 'No, do as you wished to.\n",
      "    TARGET: — No, tanto neanch’io farò in tempo — ella disse subito, e pensò: “allora si potevano disporre le cose in modo da fare come volevo io”. — No, fa’ come volevi.\n",
      " PREDICTED: giovanili giovanili giovanili giovanili giovanili giovanili giovanili giovanili giovanili giogo sbagliasse giogo sbagliasse medicine giovanili giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo credo giogo credo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo credo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo credo giogo credo credo credo giogo credo giogo credo giogo credo giogo giogo giogo credo giogo credo credo credo giogo credo giogo giogo giogo giogo giogo credo giogo credo credo credo giogo esiste esiste esiste esiste credo giogo credo giogo credo giogo credo giogo credo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo ballottaggio ballottaggio esiste giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo esempli esempli esempli esempli giogo giogo esempli esempli esempli esempli giovanili ballottaggio giovanili ballottaggio giovanili ballottaggio esiste esempli esiste esempli cocchieri giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo cocchieri giogo giogo giovanili giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giovanili giovanili giovanili giovanili giovanili giovanili ballottaggio ballottaggio giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo ballottaggio ballottaggio ballottaggio giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo esempli esempli esempli esempli credo giogo credo esempli esempli esempli esiste giogo giogo giogo giogo giogo\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "    SOURCE: We had not sat long thus, when another person came in.\n",
      "    TARGET: Ella mi trasse a sé, e restammo così in silenzio.\n",
      " PREDICTED: essendosi ballottaggio essendosi ballottaggio ballottaggio avvicinarmi ballottaggio avvicinarmi ballottaggio essendosi essendosi ballottaggio ballottaggio ballottaggio ballottaggio giogo ballottaggio giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo cocchieri giogo cocchieri giogo cocchieri giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo ballottaggio ballottaggio giogo giogo giogo giogo giogo giogo giogo giogo ballottaggio ballottaggio ballottaggio ballottaggio ballottaggio esempli ballottaggio ballottaggio ballottaggio ballottaggio ballottaggio ballottaggio ballottaggio ballottaggio ballottaggio ballottaggio ballottaggio ballottaggio ballottaggio ballottaggio ballottaggio ballottaggio ballottaggio ballottaggio giogo giogo ballottaggio ballottaggio ballottaggio ballottaggio ballottaggio ballottaggio ballottaggio ballottaggio ballottaggio ballottaggio esiste giogo giogo giogo giogo ballottaggio esempli ballottaggio esempli ballottaggio esempli ballottaggio esempli ballottaggio esempli dimissioni giogo giogo giogo giogo giogo giogo giogo giogo giogo ballottaggio giogo giogo giogo giogo giogo giogo esempli ballottaggio ballottaggio ballottaggio ballottaggio ballottaggio ballottaggio ballottaggio ballottaggio ballottaggio ballottaggio ballottaggio ballottaggio ballottaggio ballottaggio ballottaggio ballottaggio ballottaggio ballottaggio ballottaggio ballottaggio ballottaggio ballottaggio ballottaggio ballottaggio giogo ballottaggio ballottaggio ballottaggio ballottaggio ballottaggio ballottaggio ballottaggio ballottaggio ballottaggio ballottaggio ballottaggio ballottaggio ballottaggio ballottaggio ballottaggio ballottaggio ballottaggio ballottaggio ballottaggio ballottaggio ballottaggio ballottaggio ballottaggio esempli esempli esempli esempli ballottaggio ballottaggio ballottaggio ballottaggio ballottaggio ballottaggio ballottaggio ballottaggio ballottaggio ballottaggio ballottaggio ballottaggio ballottaggio ballottaggio ballottaggio ballottaggio esempli ballottaggio ballottaggio ballottaggio ballottaggio ballottaggio ballottaggio ballottaggio ballottaggio ballottaggio ballottaggio ballottaggio ballottaggio ballottaggio ballottaggio ballottaggio ballottaggio ballottaggio ballottaggio ballottaggio ballottaggio ballottaggio giogo giogo giogo giogo giogo giogo giogo giogo giogo ballottaggio ballottaggio ballottaggio ballottaggio ballottaggio ballottaggio ballottaggio giogo giogo giogo giogo giogo giogo giogo giogo giogo ballottaggio ballottaggio ballottaggio ballottaggio ballottaggio ballottaggio ballottaggio ballottaggio ballottaggio ballottaggio ballottaggio ballottaggio ballottaggio ballottaggio ballottaggio ballottaggio giogo giogo ballottaggio ballottaggio ballottaggio ballottaggio ballottaggio ballottaggio ballottaggio ballottaggio ballottaggio ballottaggio giogo giogo giogo giogo giogo giogo giogo giogo giogo giogo ballottaggio ballottaggio ballottaggio ballottaggio ballottaggio ballottaggio ballottaggio ballottaggio ballottaggio ballottaggio ballottaggio ballottaggio ballottaggio campestri campestri campestri campestri campestri ballottaggio ballottaggio ballottaggio ballottaggio esempli ballottaggio campestri ballottaggio campestri ballottaggio ballottaggio ballottaggio\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:61: FutureWarning: Importing `CharErrorRate` from `torchmetrics` was deprecated and will be removed in 2.0. Import `CharErrorRate` from `torchmetrics.text` instead.\n",
      "  _future_warning(\n",
      "/opt/conda/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:61: FutureWarning: Importing `WordErrorRate` from `torchmetrics` was deprecated and will be removed in 2.0. Import `WordErrorRate` from `torchmetrics.text` instead.\n",
      "  _future_warning(\n",
      "/opt/conda/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:61: FutureWarning: Importing `BLEUScore` from `torchmetrics` was deprecated and will be removed in 2.0. Import `BLEUScore` from `torchmetrics.text` instead.\n",
      "  _future_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "648f8f85a895423885fc9f84164e6b47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "    SOURCE: 'Oh no, I shall not be ready myself,' she said, and immediately thought: 'So it was possible to arrange things as I wished!' – 'No, do as you wished to.\n",
      "    TARGET: — No, tanto neanch’io farò in tempo — ella disse subito, e pensò: “allora si potevano disporre le cose in modo da fare come volevo io”. — No, fa’ come volevi.\n",
      " PREDICTED: — Non è un ' altra cosa , — disse , — e non è un po ’ di lui , — ma non è un ' altra cosa .\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "    SOURCE: We had not sat long thus, when another person came in.\n",
      "    TARGET: Ella mi trasse a sé, e restammo così in silenzio.\n",
      " PREDICTED: Non era stato stato , ma non si .\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean training loss at end of epoch 0 = 6.228019643075688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "    SOURCE: 'Oh no, I shall not be ready myself,' she said, and immediately thought: 'So it was possible to arrange things as I wished!' – 'No, do as you wished to.\n",
      "    TARGET: — No, tanto neanch’io farò in tempo — ella disse subito, e pensò: “allora si potevano disporre le cose in modo da fare come volevo io”. — No, fa’ come volevi.\n",
      " PREDICTED: — No , non posso dire — disse , — e , — e io non posso andare a lui . — Non posso dire , non posso dire .\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "    SOURCE: We had not sat long thus, when another person came in.\n",
      "    TARGET: Ella mi trasse a sé, e restammo così in silenzio.\n",
      " PREDICTED: Non ci si a , e si .\n",
      "--------------------------------------------------------------------------------\n",
      "Mean training loss at end of epoch 1 = 5.539486820771522\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "    SOURCE: 'Oh no, I shall not be ready myself,' she said, and immediately thought: 'So it was possible to arrange things as I wished!' – 'No, do as you wished to.\n",
      "    TARGET: — No, tanto neanch’io farò in tempo — ella disse subito, e pensò: “allora si potevano disporre le cose in modo da fare come volevo io”. — No, fa’ come volevi.\n",
      " PREDICTED: — No , non posso dire — disse Anna , e , sentendo che , come se ne fosse stato così contento di non essere così contento .\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "    SOURCE: We had not sat long thus, when another person came in.\n",
      "    TARGET: Ella mi trasse a sé, e restammo così in silenzio.\n",
      " PREDICTED: Non c ’ era mai mai mai mai mai una volta , ma non ci ci .\n",
      "--------------------------------------------------------------------------------\n",
      "Mean training loss at end of epoch 2 = 5.198262939944709\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "    SOURCE: 'Oh no, I shall not be ready myself,' she said, and immediately thought: 'So it was possible to arrange things as I wished!' – 'No, do as you wished to.\n",
      "    TARGET: — No, tanto neanch’io farò in tempo — ella disse subito, e pensò: “allora si potevano disporre le cose in modo da fare come volevo io”. — No, fa’ come volevi.\n",
      " PREDICTED: — No , non posso dire che io non — disse , e , dopo aver detto che , dopo aver detto , si — ma io non so che cosa ti .\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "    SOURCE: We had not sat long thus, when another person came in.\n",
      "    TARGET: Ella mi trasse a sé, e restammo così in silenzio.\n",
      " PREDICTED: Non ci , ma dopo un po ’ di tempo .\n",
      "--------------------------------------------------------------------------------\n",
      "Mean training loss at end of epoch 3 = 4.909002509018809\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "    SOURCE: 'Oh no, I shall not be ready myself,' she said, and immediately thought: 'So it was possible to arrange things as I wished!' – 'No, do as you wished to.\n",
      "    TARGET: — No, tanto neanch’io farò in tempo — ella disse subito, e pensò: “allora si potevano disporre le cose in modo da fare come volevo io”. — No, fa’ come volevi.\n",
      " PREDICTED: — No , non voglio venire a me — disse , e poi , dopo aver pensato , si , si sarebbe stato detto : — No , come ti ho detto .\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "    SOURCE: We had not sat long thus, when another person came in.\n",
      "    TARGET: Ella mi trasse a sé, e restammo così in silenzio.\n",
      " PREDICTED: Non avevamo ancora ancora un ’ altra volta , quando si era già addormentato .\n",
      "--------------------------------------------------------------------------------\n",
      "Mean training loss at end of epoch 4 = 4.645124032423668\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "    SOURCE: 'Oh no, I shall not be ready myself,' she said, and immediately thought: 'So it was possible to arrange things as I wished!' – 'No, do as you wished to.\n",
      "    TARGET: — No, tanto neanch’io farò in tempo — ella disse subito, e pensò: “allora si potevano disporre le cose in modo da fare come volevo io”. — No, fa’ come volevi.\n",
      " PREDICTED: — Ah , non ci , non mi pare — ella disse , e , dopo aver pensato , si diceva : — No , come io non ti .\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "    SOURCE: We had not sat long thus, when another person came in.\n",
      "    TARGET: Ella mi trasse a sé, e restammo così in silenzio.\n",
      " PREDICTED: Non avevamo ancora ancora tempo , quando ci eravamo in un ’ altra volta .\n",
      "--------------------------------------------------------------------------------\n",
      "Mean training loss at end of epoch 5 = 4.392015497168315\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "    SOURCE: 'Oh no, I shall not be ready myself,' she said, and immediately thought: 'So it was possible to arrange things as I wished!' – 'No, do as you wished to.\n",
      "    TARGET: — No, tanto neanch’io farò in tempo — ella disse subito, e pensò: “allora si potevano disporre le cose in modo da fare come volevo io”. — No, fa’ come volevi.\n",
      " PREDICTED: — Ah , no , non voglio venire da me — disse lei e cominciò subito a dire : — Ora , come ti voglio , non voglio dimenticare .\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "    SOURCE: We had not sat long thus, when another person came in.\n",
      "    TARGET: Ella mi trasse a sé, e restammo così in silenzio.\n",
      " PREDICTED: Non avevamo ancora un minuto prima quando si era ingannata .\n",
      "--------------------------------------------------------------------------------\n",
      "Mean training loss at end of epoch 6 = 4.142537443023367\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "    SOURCE: 'Oh no, I shall not be ready myself,' she said, and immediately thought: 'So it was possible to arrange things as I wished!' – 'No, do as you wished to.\n",
      "    TARGET: — No, tanto neanch’io farò in tempo — ella disse subito, e pensò: “allora si potevano disporre le cose in modo da fare come volevo io”. — No, fa’ come volevi.\n",
      " PREDICTED: — Ah , non voglio venire — disse lei , e subito continuò subito . — Ecco , come si può essere io , come ho potuto fare .\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "    SOURCE: We had not sat long thus, when another person came in.\n",
      "    TARGET: Ella mi trasse a sé, e restammo così in silenzio.\n",
      " PREDICTED: Non avevamo neppure un ’ altra volta , quando ci si fu messo a vicenda .\n",
      "--------------------------------------------------------------------------------\n",
      "Mean training loss at end of epoch 7 = 3.9050981445410815\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "    SOURCE: 'Oh no, I shall not be ready myself,' she said, and immediately thought: 'So it was possible to arrange things as I wished!' – 'No, do as you wished to.\n",
      "    TARGET: — No, tanto neanch’io farò in tempo — ella disse subito, e pensò: “allora si potevano disporre le cose in modo da fare come volevo io”. — No, fa’ come volevi.\n",
      " PREDICTED: — No , io non verrò — disse lei , e cominciò subito . — E subito , come ci sarei stato detto , come vuoi fare .\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "    SOURCE: We had not sat long thus, when another person came in.\n",
      "    TARGET: Ella mi trasse a sé, e restammo così in silenzio.\n",
      " PREDICTED: Non avevamo ancora tempo a lungo , quando l ’ un l ’ altro si udì un altro .\n",
      "--------------------------------------------------------------------------------\n",
      "Mean training loss at end of epoch 8 = 3.667943387031555\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "    SOURCE: 'Oh no, I shall not be ready myself,' she said, and immediately thought: 'So it was possible to arrange things as I wished!' – 'No, do as you wished to.\n",
      "    TARGET: — No, tanto neanch’io farò in tempo — ella disse subito, e pensò: “allora si potevano disporre le cose in modo da fare come volevo io”. — No, fa’ come volevi.\n",
      " PREDICTED: — No , non verrò da me — disse lei , e cominciò a dire : “ sì , forse , sai , sai , sai , sai , sai , sai , sai .\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "    SOURCE: We had not sat long thus, when another person came in.\n",
      "    TARGET: Ella mi trasse a sé, e restammo così in silenzio.\n",
      " PREDICTED: Non avevamo tempo a lungo , quando l ’ uno o l ’ altro .\n",
      "--------------------------------------------------------------------------------\n",
      "Mean training loss at end of epoch 9 = 3.4498925768960382\n"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    accelerator = 'gpu',\n",
    "    max_epochs = cfg['num_epochs'],\n",
    "    precision=16,\n",
    ")\n",
    "\n",
    "# Fit model\n",
    "trainer.fit(myLitmodel) #train_loader,test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

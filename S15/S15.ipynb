{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"!cd /kaggle/working","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"!rm -vrf TSAI_ERA_Assignments\n!git clone https://github.com/ToletiSri/TSAI_ERA_Assignments.git\n","metadata":{"execution":{"iopub.status.busy":"2023-08-27T08:33:06.591751Z","iopub.execute_input":"2023-08-27T08:33:06.592147Z","iopub.status.idle":"2023-08-27T08:33:10.445658Z","shell.execute_reply.started":"2023-08-27T08:33:06.592113Z","shell.execute_reply":"2023-08-27T08:33:10.444444Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Cloning into 'TSAI_ERA_Assignments'...\nremote: Enumerating objects: 413, done.\u001b[K\nremote: Counting objects: 100% (218/218), done.\u001b[K\nremote: Compressing objects: 100% (144/144), done.\u001b[K\nremote: Total 413 (delta 143), reused 106 (delta 74), pack-reused 195\u001b[K\nReceiving objects: 100% (413/413), 10.45 MiB | 19.07 MiB/s, done.\nResolving deltas: 100% (217/217), done.\n","output_type":"stream"}]},{"cell_type":"code","source":"cd TSAI_ERA_Assignments/S15","metadata":{"execution":{"iopub.status.busy":"2023-08-27T08:33:35.302517Z","iopub.execute_input":"2023-08-27T08:33:35.302910Z","iopub.status.idle":"2023-08-27T08:33:35.310425Z","shell.execute_reply.started":"2023-08-27T08:33:35.302877Z","shell.execute_reply":"2023-08-27T08:33:35.309292Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"/kaggle/working/TSAI_ERA_Assignments/S15\n","output_type":"stream"}]},{"cell_type":"code","source":"from config import get_config\ncfg = get_config()\ncfg['batch_size'] = 6\ncfg['preload'] = None\ncfg['num_epochs'] = 10","metadata":{"execution":{"iopub.status.busy":"2023-08-27T08:33:38.788221Z","iopub.execute_input":"2023-08-27T08:33:38.788578Z","iopub.status.idle":"2023-08-27T08:33:38.796086Z","shell.execute_reply.started":"2023-08-27T08:33:38.788549Z","shell.execute_reply":"2023-08-27T08:33:38.795028Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"import LightningModel\nfrom pytorch_lightning import LightningModule\n\nmyLitmodel = LightningModel.LitTransformer(cfg)\n","metadata":{"execution":{"iopub.status.busy":"2023-08-27T08:33:42.316671Z","iopub.execute_input":"2023-08-27T08:33:42.317025Z","iopub.status.idle":"2023-08-27T08:33:57.080442Z","shell.execute_reply.started":"2023-08-27T08:33:42.316997Z","shell.execute_reply":"2023-08-27T08:33:57.079420Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\nstty: 'standard input': Inappropriate ioctl for device\n","output_type":"stream"}]},{"cell_type":"code","source":"from pytorch_lightning import Trainer\n\ntrainer = Trainer(\n    accelerator = 'gpu',\n    max_epochs = cfg['num_epochs'],\n    precision=16,\n)\n\n# Fit model\ntrainer.fit(myLitmodel) #train_loader,test_loader","metadata":{"execution":{"iopub.status.busy":"2023-08-27T08:34:02.727334Z","iopub.execute_input":"2023-08-27T08:34:02.727701Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/lightning_fabric/connector.py:555: UserWarning: 16 is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!\n  rank_zero_warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/2.40k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6b3e191fdb354b87881f866ca2f0178d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading metadata:   0%|          | 0.00/7.98k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e9fa92a5047644af9b0e6bbdc0279dc2"}},"metadata":{}},{"name":"stdout","text":"Downloading and preparing dataset opus_books/en-it (download: 3.14 MiB, generated: 8.58 MiB, post-processed: Unknown size, total: 11.72 MiB) to /root/.cache/huggingface/datasets/opus_books/en-it/1.0.0/e8f950a4f32dc39b7f9088908216cd2d7e21ac35f893d04d39eb594746af2daf...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/3.30M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5cfd77203b2641bc98c48f20301b6518"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/32332 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Dataset opus_books downloaded and prepared to /root/.cache/huggingface/datasets/opus_books/en-it/1.0.0/e8f950a4f32dc39b7f9088908216cd2d7e21ac35f893d04d39eb594746af2daf. Subsequent calls will reuse this data.\nMax length of source sentence: 309\nMax length of target sentence: 274\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Sanity Checking: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  warnings.warn(_create_warning_msg(\n","output_type":"stream"},{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n--------------------------------------------------------------------------------\n    SOURCE: 'Oh, Mlle Varenka is a real angel, allez,' said Madame Berthe.\n    TARGET: — Oh, m.lle Varen’ka è un angelo del cielo, allez — replicò m.me Berthe.\n PREDICTED: successe successe Roano aspramente Roano Nikitin Nikitin Nikitin Nikitin Nikitin Nikitin Nikitin Nikitin Nikitin Nikitin Nikitin Nikitin Roano Roano successe successe successe successe successe successe successe successe successe successe successe successe Nikitin Nikitin successe successe successe successe successe successe successe spero spero successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe Nikitin Nikitin successe successe successe successe successe successe successe successe successe successe successe rimboccata rimboccata spero rimboccata rimboccata rimboccata rimboccata successe successe successe successe successe successe rimboccata rimboccata rimboccata spero rimboccata successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe rimboccata rimboccata rimboccata rimboccata successe successe rimboccata rimboccata rimboccata rimboccata rimboccata successe successe rimboccata rimboccata rimboccata rimboccata successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe rimboccata rimboccata rimboccata rimboccata rimboccata rimboccata rimboccata rimboccata rimboccata successe successe successe rimboccata rimboccata rimboccata rimboccata rimboccata rimboccata rimboccata rimboccata rimboccata rimboccata rimboccata rimboccata rimboccata rimboccata rimboccata rimboccata rimboccata rimboccata rimboccata rimboccata rimboccata rimboccata rimboccata rimboccata successe successe successe rimboccata rimboccata successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe rimboccata rimboccata rimboccata rimboccata disperare successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe successe\n--------------------------------------------------------------------------------\n--------------------------------------------------------------------------------\n    SOURCE: I have often thought about the matter since, but I have never succeeded in arriving at any satisfactory explanation of the phenomenon.\n    TARGET: Spesso, dopo, ci ho ripensato, ma non son mai riuscito a trovare una spiegazione sufficiente del fenomeno.\n PREDICTED: aspramente aspramente aspramente aspramente aspramente aspramente aspramente Nikitin Nikitin Nikitin Nikitin Nikitin Nikitin Nikitin Nikitin Nikitin Nikitin vedrà vedrà vedrà vedrà Nikitin Nikitin Nikitin Nikitin vedrà vedrà vedrà curava curava curava vedrà Nikitin vedrà curava curava curava curava vedrà vedrà vedrà vedrà vedrà curava vedrà curava vedrà vedrà vedrà vedrà vedrà vedrà vedrà curava curava curava curava curava curava curava curava curava curava curava curava curava curava curava curava curava curava curava rimboccata rimboccata rimboccata curava curava curava curava curava curava curava curava vedrà vedrà vedrà vedrà vedrà vedrà vedrà vedrà vedrà vedrà vedrà vedrà vedrà vedrà vedrà vedrà vedrà vedrà curava mercennarii curava curava curava curava curava curava curava curava curava curava curava curava vedrà vedrà vedrà curava curava curava curava curava curava curava curava curava curava curava curava mercennarii curava mercennarii curava mercennarii curava vedrà vedrà vedrà vedrà vedrà fissandomi vedrà curava scambiato direbbero successe successe successe provavano provavano provavano successe curava curava curava curava curava curava rimboccata rimboccata rimboccata rimboccata rimboccata rimboccata rimboccata curava curava curava curava curava curava curava curava curava vedrà curava curava curava curava curava curava successe successe successe successe curava curava curava curava rimboccata rimboccata rimboccata vedrà curava curava curava curava piantare successe successe successe rimboccata rimboccata rimboccata rimboccata rimboccata rimboccata rimboccata rimboccata Nikitin Nikitin Nikitin Nikitin Nikitin rimboccata rimboccata rimboccata rimboccata rimboccata rimboccata rimboccata rimboccata successe successe rimboccata rimboccata rimboccata rimboccata rimboccata rimboccata rimboccata rimboccata rimboccata rimboccata rimboccata rimboccata rimboccata rimboccata rimboccata rimboccata rimboccata rimboccata rimboccata rimboccata rimboccata curava curava vedrà vedrà vedrà curava curava curava curava curava curava curava rimboccata rimboccata rimboccata rimboccata rimboccata curava curava curava curava curava curava curava curava curava rimboccata rimboccata rimboccata rimboccata rimboccata rimboccata curava curava curava rimboccata rimboccata rimboccata rimboccata rimboccata rimboccata rimboccata rimboccata rimboccata rimboccata rimboccata rimboccata rimboccata vedrà fissandomi vedrà rimboccata rimboccata rimboccata rimboccata rimboccata rimboccata rimboccata rimboccata curava curava curava curava curava curava curava curava rimboccata rimboccata vedrà fissandomi vedrà fissandomi vedrà scossero rimboccata rimboccata scossero scossero scossero scossero scossero rimboccata rimboccata rimboccata scossero scossero curava metterla metterla metterla metterla curava metterla metterla metterla metterla metterla metterla curava metterla metterla metterla\n--------------------------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:61: FutureWarning: Importing `CharErrorRate` from `torchmetrics` was deprecated and will be removed in 2.0. Import `CharErrorRate` from `torchmetrics.text` instead.\n  _future_warning(\n/opt/conda/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:61: FutureWarning: Importing `WordErrorRate` from `torchmetrics` was deprecated and will be removed in 2.0. Import `WordErrorRate` from `torchmetrics.text` instead.\n  _future_warning(\n/opt/conda/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:61: FutureWarning: Importing `BLEUScore` from `torchmetrics` was deprecated and will be removed in 2.0. Import `BLEUScore` from `torchmetrics.text` instead.\n  _future_warning(\n","output_type":"stream"},{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"12caacafa851490096c47d3d6c3c7682"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"--------------------------------------------------------------------------------\n    SOURCE: 'Oh, Mlle Varenka is a real angel, allez,' said Madame Berthe.\n    TARGET: — Oh, m.lle Varen’ka è un angelo del cielo, allez — replicò m.me Berthe.\n PREDICTED: — Sì , — disse Levin .\n--------------------------------------------------------------------------------\n--------------------------------------------------------------------------------\n    SOURCE: I have often thought about the matter since, but I have never succeeded in arriving at any satisfactory explanation of the phenomenon.\n    TARGET: Spesso, dopo, ci ho ripensato, ma non son mai riuscito a trovare una spiegazione sufficiente del fenomeno.\n PREDICTED: Non mi , ma non mi , ma non mi , ma non mi .\n--------------------------------------------------------------------------------\nLoss at end of epoch 0 = 5.867561340332031\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"--------------------------------------------------------------------------------\n    SOURCE: 'Oh, Mlle Varenka is a real angel, allez,' said Madame Berthe.\n    TARGET: — Oh, m.lle Varen’ka è un angelo del cielo, allez — replicò m.me Berthe.\n PREDICTED: — Ah , va bene — disse , — e , sorridendo .\n--------------------------------------------------------------------------------\n--------------------------------------------------------------------------------\n    SOURCE: I have often thought about the matter since, but I have never succeeded in arriving at any satisfactory explanation of the phenomenon.\n    TARGET: Spesso, dopo, ci ho ripensato, ma non son mai riuscito a trovare una spiegazione sufficiente del fenomeno.\n PREDICTED: Io non mi , ma non mi , ma non mi , ma non mi .\n--------------------------------------------------------------------------------\nLoss at end of epoch 1 = 5.405826568603516\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"--------------------------------------------------------------------------------\n    SOURCE: 'Oh, Mlle Varenka is a real angel, allez,' said Madame Berthe.\n    TARGET: — Oh, m.lle Varen’ka è un angelo del cielo, allez — replicò m.me Berthe.\n PREDICTED: — Oh , Harris , — disse la signora Reed .\n--------------------------------------------------------------------------------\n--------------------------------------------------------------------------------\n    SOURCE: I have often thought about the matter since, but I have never succeeded in arriving at any satisfactory explanation of the phenomenon.\n    TARGET: Spesso, dopo, ci ho ripensato, ma non son mai riuscito a trovare una spiegazione sufficiente del fenomeno.\n PREDICTED: Io ho avuto una cosa simile a questo , ma non ho mai avuto una cosa simile a un ’ altra cosa .\n--------------------------------------------------------------------------------\nLoss at end of epoch 2 = 4.406838893890381\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"--------------------------------------------------------------------------------\n    SOURCE: 'Oh, Mlle Varenka is a real angel, allez,' said Madame Berthe.\n    TARGET: — Oh, m.lle Varen’ka è un angelo del cielo, allez — replicò m.me Berthe.\n PREDICTED: — Ah , Varen ’ ka , è un bambino — disse la signora .\n--------------------------------------------------------------------------------\n--------------------------------------------------------------------------------\n    SOURCE: I have often thought about the matter since, but I have never succeeded in arriving at any satisfactory explanation of the phenomenon.\n    TARGET: Spesso, dopo, ci ho ripensato, ma non son mai riuscito a trovare una spiegazione sufficiente del fenomeno.\n PREDICTED: Io ho detto che la prima volta non ho mai fatto mai nulla , ma non ho mai fatto neppure il tempo di .\n--------------------------------------------------------------------------------\nLoss at end of epoch 3 = 5.066241264343262\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"--------------------------------------------------------------------------------\n    SOURCE: 'Oh, Mlle Varenka is a real angel, allez,' said Madame Berthe.\n    TARGET: — Oh, m.lle Varen’ka è un angelo del cielo, allez — replicò m.me Berthe.\n PREDICTED: — Ah , mamma è un uomo buono , — disse la signora .\n--------------------------------------------------------------------------------\n--------------------------------------------------------------------------------\n    SOURCE: I have often thought about the matter since, but I have never succeeded in arriving at any satisfactory explanation of the phenomenon.\n    TARGET: Spesso, dopo, ci ho ripensato, ma non son mai riuscito a trovare una spiegazione sufficiente del fenomeno.\n PREDICTED: Io ho detto che non ho mai pensato a nessuno , ma non ho mai preso a parlare di quel momento .\n--------------------------------------------------------------------------------\nLoss at end of epoch 4 = 3.899146556854248\n","output_type":"stream"},{"text":"IOPub message rate exceeded.\nThe notebook server will temporarily stop sending output\nto the client in order to avoid crashing it.\nTo change this limit, set the config variable\n`--NotebookApp.iopub_msg_rate_limit`.\n\nCurrent values:\nNotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\nNotebookApp.rate_limit_window=3.0 (secs)\n\nIOPub message rate exceeded.\nThe notebook server will temporarily stop sending output\nto the client in order to avoid crashing it.\nTo change this limit, set the config variable\n`--NotebookApp.iopub_msg_rate_limit`.\n\nCurrent values:\nNotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\nNotebookApp.rate_limit_window=3.0 (secs)\n\n","name":"stderr","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"--------------------------------------------------------------------------------\n    SOURCE: 'Oh, Mlle Varenka is a real angel, allez,' said Madame Berthe.\n    TARGET: — Oh, m.lle Varen’ka è un angelo del cielo, allez — replicò m.me Berthe.\n PREDICTED: — Ah , cara , una ragazza bella , buona , cara signora !\n--------------------------------------------------------------------------------\n--------------------------------------------------------------------------------\n    SOURCE: I have often thought about the matter since, but I have never succeeded in arriving at any satisfactory explanation of the phenomenon.\n    TARGET: Spesso, dopo, ci ho ripensato, ma non son mai riuscito a trovare una spiegazione sufficiente del fenomeno.\n PREDICTED: Ho pensato di non aver mai pensato , ma non ho mai avuto il diritto di il quadro .\n--------------------------------------------------------------------------------\nLoss at end of epoch 5 = 4.20262336730957\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"--------------------------------------------------------------------------------\n    SOURCE: 'Oh, Mlle Varenka is a real angel, allez,' said Madame Berthe.\n    TARGET: — Oh, m.lle Varen’ka è un angelo del cielo, allez — replicò m.me Berthe.\n PREDICTED: — Sì , Tanja è un , è un — disse la signora .\n--------------------------------------------------------------------------------\n--------------------------------------------------------------------------------\n    SOURCE: I have often thought about the matter since, but I have never succeeded in arriving at any satisfactory explanation of the phenomenon.\n    TARGET: Spesso, dopo, ci ho ripensato, ma non son mai riuscito a trovare una spiegazione sufficiente del fenomeno.\n PREDICTED: Ho pensato che avevo pensato , ma non ho mai fatto che non ho mai fatto che il mio ritorno .\n--------------------------------------------------------------------------------\nLoss at end of epoch 6 = 4.077297210693359\n","output_type":"stream"}]},{"cell_type":"code","source":"pwd","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}